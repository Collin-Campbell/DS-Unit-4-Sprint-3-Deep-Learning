{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "U4-S3-MNA-DS11",
      "language": "python",
      "name": "u4-s3-mna-ds11"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.0",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "nteract": {
      "version": "0.23.3"
    },
    "colab": {
      "name": "LS_DS_431_RNN_and_LSTM_Assignment.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Collin-Campbell/DS-Unit-4-Sprint-3-Deep-Learning/blob/main/module1-rnn-and-lstm/LS_DS_431_RNN_and_LSTM_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M2RmnkWsk-gG"
      },
      "source": [
        "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
        "<br></br>\n",
        "<br></br>\n",
        "\n",
        "## *Data Science Unit 4 Sprint 3 Assignment 1*\n",
        "\n",
        "# Recurrent Neural Networks and Long Short Term Memory (LSTM)\n",
        "\n",
        "![Monkey at a typewriter](https://upload.wikimedia.org/wikipedia/commons/thumb/3/3c/Chimpanzee_seated_at_typewriter.jpg/603px-Chimpanzee_seated_at_typewriter.jpg)\n",
        "\n",
        "It is said that [infinite monkeys typing for an infinite amount of time](https://en.wikipedia.org/wiki/Infinite_monkey_theorem) will eventually type, among other things, the complete works of Wiliam Shakespeare. Let's see if we can get there a bit faster, with the power of Recurrent Neural Networks and LSTM.\n",
        "\n",
        "This text file contains the complete works of Shakespeare: https://www.gutenberg.org/files/100/100-0.txt\n",
        "\n",
        "Use it as training data for an RNN - you can keep it simple and train character level, and that is suggested as an initial approach.\n",
        "\n",
        "Then, use that trained RNN to generate Shakespearean-ish text. Your goal - a function that can take, as an argument, the size of text (e.g. number of characters or lines) to generate, and returns generated text of that size.\n",
        "\n",
        "Note - Shakespeare wrote an awful lot. It's OK, especially initially, to sample/use smaller data and parameters, so you can have a tighter feedback loop when you're trying to get things running. Then, once you've got a proof of concept - start pushing it more!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2020-06-15T18:18:20.442Z",
          "iopub.execute_input": "2020-06-15T18:18:20.453Z",
          "iopub.status.idle": "2020-06-15T18:18:20.513Z",
          "shell.execute_reply": "2020-06-15T18:18:20.523Z"
        },
        "id": "VJzvaa_vk-gR"
      },
      "source": [
        "import requests\n",
        "import pandas as pd"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2020-06-15T18:25:49.778Z",
          "iopub.execute_input": "2020-06-15T18:25:49.781Z",
          "iopub.status.idle": "2020-06-15T18:25:51.467Z",
          "shell.execute_reply": "2020-06-15T18:25:51.469Z"
        },
        "id": "-nT-tPdlk-gS"
      },
      "source": [
        "url = \"https://www.gutenberg.org/files/100/100-0.txt\"\n",
        "\n",
        "r = requests.get(url)\n",
        "r.encoding = r.apparent_encoding\n",
        "data = r.text\n",
        "data = data.split('\\r\\n')\n",
        "toc = [l.strip() for l in data[44:130:2]]\n",
        "# Skip the Table of Contents\n",
        "data = data[135:]\n",
        "\n",
        "# Fixing Titles\n",
        "toc[9] = 'THE LIFE OF KING HENRY V'\n",
        "toc[18] = 'MACBETH'\n",
        "toc[24] = 'OTHELLO, THE MOOR OF VENICE'\n",
        "toc[34] = 'TWELFTH NIGHT: OR, WHAT YOU WILL'\n",
        "\n",
        "locations = {id_:{'title':title, 'start':-99} for id_,title in enumerate(toc)}\n",
        "\n",
        "# Start \n",
        "for e,i in enumerate(data):\n",
        "    for t,title in enumerate(toc):\n",
        "        if title in i:\n",
        "            locations[t].update({'start':e})\n",
        "            \n",
        "\n",
        "df_toc = pd.DataFrame.from_dict(locations, orient='index')\n",
        "df_toc['end'] = df_toc['start'].shift(-1).apply(lambda x: x-1)\n",
        "df_toc.loc[42, 'end'] = len(data)\n",
        "df_toc['end'] = df_toc['end'].astype('int')\n",
        "\n",
        "df_toc['text'] = df_toc.apply(lambda x: '\\r\\n'.join(data[ x['start'] : int(x['end']) ]), axis=1)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "execution": {
          "iopub.status.busy": "2020-06-15T18:26:12.630Z",
          "iopub.execute_input": "2020-06-15T18:26:12.637Z",
          "iopub.status.idle": "2020-06-15T18:26:12.643Z",
          "shell.execute_reply": "2020-06-15T18:26:12.647Z"
        },
        "id": "IKNhyd2lk-gT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "56bd54dc-d381-478b-ec46-fc674b4a66e2"
      },
      "source": [
        "#Shakespeare Data Parsed by Play\n",
        "df_toc.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>start</th>\n",
              "      <th>end</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>THE TRAGEDY OF ANTONY AND CLEOPATRA</td>\n",
              "      <td>-99</td>\n",
              "      <td>14379</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>AS YOU LIKE IT</td>\n",
              "      <td>14380</td>\n",
              "      <td>17171</td>\n",
              "      <td>AS YOU LIKE IT\\r\\n\\r\\n\\r\\nDRAMATIS PERSONAE.\\r...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>THE COMEDY OF ERRORS</td>\n",
              "      <td>17172</td>\n",
              "      <td>20372</td>\n",
              "      <td>THE COMEDY OF ERRORS\\r\\n\\r\\n\\r\\n\\r\\nContents\\r...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>THE TRAGEDY OF CORIOLANUS</td>\n",
              "      <td>20373</td>\n",
              "      <td>30346</td>\n",
              "      <td>THE TRAGEDY OF CORIOLANUS\\r\\n\\r\\nDramatis Pers...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>CYMBELINE</td>\n",
              "      <td>30347</td>\n",
              "      <td>30364</td>\n",
              "      <td>CYMBELINE.\\r\\nLaud we the gods;\\r\\nAnd let our...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                 title  ...                                               text\n",
              "0  THE TRAGEDY OF ANTONY AND CLEOPATRA  ...                                                   \n",
              "1                       AS YOU LIKE IT  ...  AS YOU LIKE IT\\r\\n\\r\\n\\r\\nDRAMATIS PERSONAE.\\r...\n",
              "2                 THE COMEDY OF ERRORS  ...  THE COMEDY OF ERRORS\\r\\n\\r\\n\\r\\n\\r\\nContents\\r...\n",
              "3            THE TRAGEDY OF CORIOLANUS  ...  THE TRAGEDY OF CORIOLANUS\\r\\n\\r\\nDramatis Pers...\n",
              "4                            CYMBELINE  ...  CYMBELINE.\\r\\nLaud we the gods;\\r\\nAnd let our...\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9luOaBVJsAsn"
      },
      "source": [
        "data2 = []\n",
        "\n",
        "for s in data:\n",
        "  data2.append(s.strip())"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97KuRk8IukaZ"
      },
      "source": [
        "data3 = []\n",
        "\n",
        "for s in data2:\n",
        "  if s.isdigit() == False:\n",
        "    data3.append(s)\n",
        "  else:\n",
        "    continue"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lAOZmOVcvX4r"
      },
      "source": [
        "data4 = []\n",
        "\n",
        "for s in data3:\n",
        "  if s != '':\n",
        "    data4.append(s)\n",
        "  else:\n",
        "    continue"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "At4kPqZs1PYq"
      },
      "source": [
        "data4 = data4[:140036] # removing credits in the text "
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y3iI3S5ovq3x"
      },
      "source": [
        "full_text = ''\n",
        "\n",
        "for s in data4:\n",
        "  full_text += ' ' + s\n"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51fQT1e9wHIx"
      },
      "source": [
        "full_text = full_text.strip()"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RtXbZdY-wSEY"
      },
      "source": [
        "new_list = []\n",
        "\n",
        "for i in full_text.split():\n",
        "  if i.isdigit() == False:\n",
        "    new_list.append(i)\n",
        "\n",
        "final_text = ''\n",
        "\n",
        "for s in new_list:\n",
        "  final_text += ' ' + s\n",
        "\n",
        "final_text = final_text.strip()"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OqwoUsI83uxV",
        "outputId": "0c88777e-7b84-4e9e-c104-fbf8d0c200ac"
      },
      "source": [
        "# Encode Data as Chars\n",
        "\n",
        "# Find the unique characters\n",
        "chars = list(set(final_text))\n",
        "\n",
        "# Lookup tables\n",
        "char_int = {c:i for i, c in enumerate(chars)} \n",
        "int_char = {i:c for i, c in enumerate(chars)}\n",
        "\n",
        "print('The number of unique characters in the text:', len(chars))"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The number of unique characters in the text: 99\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2w9gy_0i4Lv1",
        "outputId": "e3035d16-734b-416a-b1c5-32b2d19c5c9f"
      },
      "source": [
        "# Create the sequence data\n",
        "maxlen = 30\n",
        "step = 5\n",
        "\n",
        "# Encode the characters using the lookup tables\n",
        "encoded = [char_int[c] for c in final_text]\n",
        "\n",
        "# Initialize empty lists to hold the sequences\n",
        "sequences = [] # Each element is 40 chars long\n",
        "next_char = [] # One element for each sequence\n",
        "\n",
        "# Loop through the entire text\n",
        "for i in range(0, len(encoded) - maxlen, step): \n",
        "    sequences.append(encoded[i : i + maxlen])\n",
        "    next_char.append(encoded[i + maxlen])\n",
        "\n",
        "print('sequences: ', len(sequences))"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sequences:  1051537\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0iFtOPg4fLS"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "\n",
        "# Pad sequences so all are equal\n",
        "seq = tf.keras.preprocessing.sequence.pad_sequences(sequences, maxlen=30)\n",
        "\n",
        "# Create x & y\n",
        "import numpy as np\n",
        "\n",
        "# Create arrays of zeros (False)\n",
        "x = np.zeros((len(sequences), maxlen, len(chars)), dtype=np.bool)\n",
        "y = np.zeros((len(sequences), len(chars)), dtype=np.bool)\n",
        "\n",
        "# Turn on the location (set to True) when the character is present\n",
        "for i, sequence in enumerate(sequences):\n",
        "    for t, char in enumerate(sequence):\n",
        "        x[i,t,char] = 1\n",
        "\n",
        "    y[i, next_char[i]] = 1"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygAWZtMa4vFr"
      },
      "source": [
        "# Build the model: a single LSTM\n",
        "from keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM\n",
        "from tensorflow.keras.layers import Bidirectional, Embedding\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(output_dim=64, input_dim=len(chars)))\n",
        "model.add(Bidirectional(LSTM(64)))\n",
        "model.add(Dense(len(chars), activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u9sDNK6o5L1l",
        "outputId": "4a460a0d-6dbb-4271-9b37-7c41204aaf22"
      },
      "source": [
        "# Fit the model\n",
        "model.fit(seq, y, batch_size=32,\n",
        "          epochs=30, verbose=2)\n"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "32861/32861 - 814s - loss: 1.6995\n",
            "Epoch 2/30\n",
            "32861/32861 - 817s - loss: 1.6685\n",
            "Epoch 3/30\n",
            "32861/32861 - 815s - loss: 1.6469\n",
            "Epoch 4/30\n",
            "32861/32861 - 816s - loss: 1.6303\n",
            "Epoch 5/30\n",
            "32861/32861 - 814s - loss: 1.6175\n",
            "Epoch 6/30\n",
            "32861/32861 - 813s - loss: 1.6064\n",
            "Epoch 7/30\n",
            "32861/32861 - 811s - loss: 1.5970\n",
            "Epoch 8/30\n",
            "32861/32861 - 815s - loss: 1.5889\n",
            "Epoch 9/30\n",
            "32861/32861 - 814s - loss: 1.5820\n",
            "Epoch 10/30\n",
            "32861/32861 - 812s - loss: 1.5760\n",
            "Epoch 11/30\n",
            "32861/32861 - 813s - loss: 1.5708\n",
            "Epoch 12/30\n",
            "32861/32861 - 813s - loss: 1.5659\n",
            "Epoch 13/30\n",
            "32861/32861 - 812s - loss: 1.5617\n",
            "Epoch 14/30\n",
            "32861/32861 - 815s - loss: 1.5581\n",
            "Epoch 15/30\n",
            "32861/32861 - 814s - loss: 1.5550\n",
            "Epoch 16/30\n",
            "32861/32861 - 811s - loss: 1.5515\n",
            "Epoch 17/30\n",
            "32861/32861 - 813s - loss: 1.5489\n",
            "Epoch 18/30\n",
            "32861/32861 - 812s - loss: 1.5467\n",
            "Epoch 19/30\n",
            "32861/32861 - 813s - loss: 1.5437\n",
            "Epoch 20/30\n",
            "32861/32861 - 814s - loss: 1.5417\n",
            "Epoch 21/30\n",
            "32861/32861 - 804s - loss: 1.5392\n",
            "Epoch 22/30\n",
            "32861/32861 - 805s - loss: 1.5370\n",
            "Epoch 23/30\n",
            "32861/32861 - 809s - loss: 1.5352\n",
            "Epoch 24/30\n",
            "32861/32861 - 816s - loss: 1.5334\n",
            "Epoch 25/30\n",
            "32861/32861 - 813s - loss: 1.5313\n",
            "Epoch 26/30\n",
            "32861/32861 - 814s - loss: 1.5297\n",
            "Epoch 27/30\n",
            "32861/32861 - 813s - loss: 1.5281\n",
            "Epoch 28/30\n",
            "32861/32861 - 814s - loss: 1.5273\n",
            "Epoch 29/30\n",
            "32861/32861 - 811s - loss: 1.5255\n",
            "Epoch 30/30\n",
            "32861/32861 - 819s - loss: 1.5249\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
            "INFO:tensorflow:Assets written to: ShakespeareBot/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "at2U8Ryc_yP7"
      },
      "source": [
        "model.save('ShakespeareBot')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NUvnho6Z_6aS"
      },
      "source": [
        "from tensorflow import keras\n",
        "model = keras.models.load_model('ShakespeareBot')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EXoPInic6Bcc"
      },
      "source": [
        "# Predict and convert text back into characters\n",
        "def generate_text(model, seed, length):\n",
        "\n",
        "  encoded = [char_int[c] for c in seed]\n",
        "\n",
        "  generated = ''\n",
        "  generated += seed\n",
        "  model.reset_states()\n",
        "\n",
        "  start_index = 0 \n",
        "\n",
        "  for _ in range(length):\n",
        "\n",
        "      sample = encoded[start_index:start_index+10]      \n",
        "      sample = np.array(sample)\n",
        "      sample = np.expand_dims(sample,0)\n",
        "\n",
        "      pred = model.predict(sample)\n",
        "      pred = tf.squeeze(pred, 0)\n",
        "      next_char = np.argmax(pred)\n",
        "      encoded.append(next_char)\n",
        "      generated += int_char[next_char]\n",
        "\n",
        "      start_index += 1\n",
        "\n",
        "  return generated"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "jqpnUJbviylP",
        "outputId": "9549365e-ad81-4319-90a8-9fa02ef6f854"
      },
      "source": [
        "seed_text = \"HAMLET: \"\n",
        "\n",
        "generate_text(model, seed_text, 30)"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'HAMLET: So I wilt thee and the VALLET '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zE4a4O7Bp5x1"
      },
      "source": [
        "# Resources and Stretch Goals"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uT3UV3gap9H6"
      },
      "source": [
        "## Stretch goals:\n",
        "- Refine the training and generation of text to be able to ask for different genres/styles of Shakespearean text (e.g. plays versus sonnets)\n",
        "- Train a classification model that takes text and returns which work of Shakespeare it is most likely to be from\n",
        "- Make it more performant! Many possible routes here - lean on Keras, optimize the code, and/or use more resources (AWS, etc.)\n",
        "- Revisit the news example from class, and improve it - use categories or tags to refine the model/generation, or train a news classifier\n",
        "- Run on bigger, better data\n",
        "\n",
        "## Resources:\n",
        "- [The Unreasonable Effectiveness of Recurrent Neural Networks](https://karpathy.github.io/2015/05/21/rnn-effectiveness/) - a seminal writeup demonstrating a simple but effective character-level NLP RNN\n",
        "- [Simple NumPy implementation of RNN](https://github.com/JY-Yoon/RNN-Implementation-using-NumPy/blob/master/RNN%20Implementation%20using%20NumPy.ipynb) - Python 3 version of the code from \"Unreasonable Effectiveness\"\n",
        "- [TensorFlow RNN Tutorial](https://github.com/tensorflow/models/tree/master/tutorials/rnn) - code for training a RNN on the Penn Tree Bank language dataset\n",
        "- [4 part tutorial on RNN](http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-1-introduction-to-rnns/) - relates RNN to the vanishing gradient problem, and provides example implementation\n",
        "- [RNN training tips and tricks](https://github.com/karpathy/char-rnn#tips-and-tricks) - some rules of thumb for parameterizing and training your RNN"
      ]
    }
  ]
}